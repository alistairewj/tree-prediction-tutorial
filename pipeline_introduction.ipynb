{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI3bzd4hGSFb"
      },
      "source": [
        "# Pipeline\n",
        "\n",
        "The goal of this notebook is to learn about sklearn's pipeline and some useful data science tips."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_s5R2dgGSFk"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from datetime import timedelta\n",
        "import collections\n",
        "import os\n",
        "import errno\n",
        "\n",
        "import sklearn\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import datasets\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydotplus\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# used to display trees\n",
        "from IPython.display import Image\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "plt.rcParams.update({'font.size': 20})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_colormap(seq):\n",
        "    \"\"\"Return a LinearSegmentedColormap\n",
        "    seq: a sequence of floats and RGB-tuples. The floats should be increasing\n",
        "    and in the interval (0,1).\n",
        "    \"\"\"\n",
        "    seq = [(None,) * 3, 0.0] + list(seq) + [1.0, (None,) * 3]\n",
        "    cdict = {'red': [], 'green': [], 'blue': []}\n",
        "    for i, item in enumerate(seq):\n",
        "        if isinstance(item, float):\n",
        "            r1, g1, b1 = seq[i - 1]\n",
        "            r2, g2, b2 = seq[i + 1]\n",
        "            cdict['red'].append([item, r1, r2])\n",
        "            cdict['green'].append([item, g1, g2])\n",
        "            cdict['blue'].append([item, b1, b2])\n",
        "    return matplotlib.colors.LinearSegmentedColormap('CustomMap', cdict)\n",
        "\n",
        "def plot_model_pred_2d(mdl, X, y, cm=None, cbar=True, xlabel=None, ylabel=None):\n",
        "    # look at the regions in a 2d plot\n",
        "    # based on scikit-learn tutorial plot_iris.html\n",
        "\n",
        "    # get minimum and maximum values\n",
        "    x0_min = X[:, 0].min()\n",
        "    x0_max = X[:, 0].max()\n",
        "    x1_min = X[:, 1].min()\n",
        "    x1_max = X[:, 1].max()\n",
        "\n",
        "    xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 100),\n",
        "                         np.linspace(x1_min, x1_max, 100))\n",
        "\n",
        "    Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    if not cm:\n",
        "        # custom colormap\n",
        "        #e58139f9 - orange\n",
        "        #399de5e0 - to blue\n",
        "        s = list()\n",
        "\n",
        "        lo = np.array(matplotlib.colors.to_rgb('#e5813900'))\n",
        "        hi = np.array(matplotlib.colors.to_rgb('#399de5e0'))\n",
        "\n",
        "        for i in range(255):\n",
        "            s.append( list((hi-lo)*(float(i)/255)+lo) )\n",
        "        cm = make_colormap(s)\n",
        "\n",
        "    # plot the contour - colouring different regions\n",
        "    cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
        "\n",
        "    # plot the individual data points - colouring by the *true* outcome\n",
        "    color = y.ravel()\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k', linewidth=2,\n",
        "                marker='o', s=60, cmap=cm)\n",
        "\n",
        "    if xlabel is not None:\n",
        "        plt.xlabel(xlabel)\n",
        "    if ylabel is not None:\n",
        "        plt.ylabel(ylabel)\n",
        "    plt.axis(\"tight\")\n",
        "    #plt.clim([-1.5,1.5])\n",
        "    if cbar:\n",
        "        plt.colorbar()\n",
        "\n",
        "def create_graph(mdl, cmap=None, feat=None):\n",
        "    # cmap is a colormap\n",
        "    # e.g. cmap = matplotlib.cm.coolwarm( np.linspace(0.0, 1.0, 256, dtype=float) )\n",
        "    tree_graph = tree.export_graphviz(mdl, out_file=None,\n",
        "                             feature_names=feat,\n",
        "                             filled=True, rounded=True)\n",
        "    graph = pydotplus.graphviz.graph_from_dot_data(tree_graph)\n",
        "\n",
        "    # get colormap\n",
        "    if cmap:\n",
        "        # remove transparency\n",
        "        if cmap.shape[1]==4:\n",
        "            cmap = cmap[:,0:2]\n",
        "\n",
        "        nodes = graph.get_node_list()\n",
        "        for node in nodes:\n",
        "            if node.get_label():\n",
        "                # get number of samples in group 1 and group 2\n",
        "                num_samples = [int(ii) for ii in node.get_label().split('value = [')[1].split(']')[0].split(',')]\n",
        "\n",
        "                # proportion that is class 2\n",
        "                cm_value = float(num_samples[1]) / float(sum(num_samples))\n",
        "                # convert to (R, G, B, alpha) tuple\n",
        "                cm_value = matplotlib.cm.coolwarm(cm_value)\n",
        "                cm_value = [int(np.ceil(255*x)) for x in cm_value]\n",
        "                color = '#{:02x}{:02x}{:02x}'.format(cm_value[0], cm_value[1], cm_value[2])\n",
        "                node.set_fillcolor(color)\n",
        "\n",
        "    Image(graph.create_png())\n",
        "    return graph"
      ],
      "metadata": {
        "id": "2jzzHqg_SEmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise\n",
        "\n",
        "We'll practice using pipeline on a dataset acquired from patients admitted to intensive care units at the Beth Israel Deaconness Medical Center in Boston, MA. All patients in the cohort stayed for at least 48 hours, and the goal of the prediction task is to predict in-hospital mortality. This data is a subset of a publicly accessible ICU database: MIMIC. If you're interested, you can read more about MIMIC [here](https://mimic.physionet.org).\n",
        "The particular dataset we are using is described in more detail here: http://physionet.org/challenge/2012/\n",
        "\n",
        "The data is originally provided as a time series of observations for a number of variables, but to simplify the analysis, we've done some preprocessing to get a single row for each patient.\n",
        "The following cell will check if the data is available here. If it's not, it will download it to the subfolder `data` in the same folder as this notebook.\n",
        "\n",
        "The goal of this challenge was to predict mortality, i.e. whether a patient died in the hospital at the end of their stay."
      ],
      "metadata": {
        "id": "V9Rpf2dbPYF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://github.com/alistairewj/tree-prediction-tutorial/raw/master/data/PhysionetChallenge2012-set-a.csv.gz'\n",
        "seta = pd.read_csv(url, sep=',', header=0, compression='gzip')\n",
        "seta.set_index('recordid', inplace=True)\n",
        "seta.head()"
      ],
      "metadata": {
        "id": "DtKWMJ9jGKA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, we can see we have a few variables:\n",
        "\n",
        "- SAPS-I\n",
        "- SOFA\n",
        "- Length_of_stay\n",
        "- Survival\n",
        "- In-hospital_death\n",
        "- Age\n",
        "- Gender\n",
        "- Height\n",
        "- Weight\n",
        "- CCU\n",
        "- ...\n",
        "\n",
        "Q1: How would I understand what these variables mean?"
      ],
      "metadata": {
        "id": "mJm6IorcQCDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A1: Look at the documentation! http://physionet.org/challenge/2012/"
      ],
      "metadata": {
        "id": "SxVW_4PqQWcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avoid data leakage\n",
        "\n",
        "Our first step will be to really understand our data through EDA. We can look at all the columns. Since there's so many, we print 10 per row."
      ],
      "metadata": {
        "id": "sTj54ZedPhKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print all the columns\n",
        "for i in range(0, len(seta.columns), 10):\n",
        "  print(list(seta.columns[i:i+10]))"
      ],
      "metadata": {
        "id": "QyeJrO98R0QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2: Are there columns which would cause data leakage?"
      ],
      "metadata": {
        "id": "reUaCZ7iTuBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A2: Yes! We should not use the survival column for in-hospital mortality prediction."
      ],
      "metadata": {
        "id": "GDPca41iTvqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative A2: We can see this with a decision tree.\n",
        "mdl = ensemble.GradientBoostingClassifier(n_estimators=10)\n",
        "X, y = seta[['Length_of_stay']].values, seta[['In-hospital_death']].values\n",
        "mdl = tree.DecisionTreeClassifier(max_depth=1)\n",
        "mdl = mdl.fit(X,y)\n",
        "graph = create_graph(mdl, feat=['Length_of_stay'])\n",
        "Image(graph.create_png())"
      ],
      "metadata": {
        "id": "6ysWlLFpT_pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove cheating variables from training data\n",
        "X = seta.drop(['In-hospital_death', 'Survival', 'Length_of_stay'], axis=1).values\n",
        "features = list(seta.drop(['In-hospital_death', 'Survival', 'Length_of_stay'], axis=1).columns)\n",
        "y = seta['In-hospital_death'].values"
      ],
      "metadata": {
        "id": "Pepl_2HMT6yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are trying to build a machine learning model to predict an outcome. We would like this to work in the real world when we go out and use it. To do this, we need to estimate the *generalization* error of our model, which we approximate with the error on a set of data we have.\n",
        "\n",
        "Q3: Why can't we just use the entire dataset to do this? That is, why can't we just do:\n",
        "\n",
        "```python\n",
        "model = train_model(data, target)\n",
        "score = score_model(model, data, target)\n",
        "print(f'My amazing score is: {score}!')\n",
        "```"
      ],
      "metadata": {
        "id": "gOotvIa5STHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A3: Evaluating models on the same data they've been trained on is optimistic and misleading.\n",
        "\n",
        "Models vary in their amount of flexibility (in statistics, we sometimes say models are high variance, which is somewhat confusing terminology). It can be helpful to imagine two extreme scenarios. Imagine our model always predicts the average of the outcome, which in this case is 15%:\n",
        "\n",
        "```python\n",
        "model = lambda x: return 0.15\n",
        "```\n",
        "\n",
        "Every time we ask the model to predict mortality for a patient, it returns 0.15. It doesn't matter what data we provide, this model won't overfit.\n",
        "\n",
        "Now imagine a model that memorizes the data and returns the result it's already seen:\n",
        "\n",
        "```python\n",
        "model = lambda x: return target[x]\n",
        "```\n",
        "\n",
        "This model will perfectly predict our training set, but will do terribly on any external dataset.\n",
        "\n",
        "For this reason, we hold out some data for evaluation."
      ],
      "metadata": {
        "id": "PiUuyyWmSwfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here we only use the first 3000 observations as our training set\n",
        "y_train = y[0:3000]\n",
        "X_train = X[0:3000, :]\n",
        "\n",
        "y_test = y[3000:]\n",
        "X_test = X[3000:, :]\n",
        "\n",
        "print('Training size: {} - {:6d} missing observations'.format(X_train.shape,\n",
        "                                                           np.sum(np.sum(np.isnan(X_train)))))\n",
        "print('Test size:     {} - {:6d} missing observations'.format(X_test.shape,\n",
        "                                 np.sum(np.sum(np.isnan(X_test)))))"
      ],
      "metadata": {
        "id": "QOYz3uR8Tpmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Missing data\n",
        "\n",
        "The outcome is the first column `'In-hospital_death'`. Most of the rest of the data are features we can use to predict this binary outcome (while avoiding data leakage).\n",
        "\n",
        "You'll note that the above has a lot of missing data! It is a challenging issue with medical data. In general there are three types of missing data:\n",
        "\n",
        "1. Missing completely at random (MCAR)\n",
        "    * The data is missing for reasons *unrelated* to the data\n",
        "    * a power outage results in losing vital sign data\n",
        "2. Missing at random (MAR)\n",
        "    * The data is missing for reasons related to the data, but not the missing observation\n",
        "    * we don't collect lactate measurements on admission to a medical ICU, but we collect them for cardiac ICU\n",
        "3. Missing not at random (MNAR)\n",
        "    * The data is missing, and the reason it is missing *depends* on the value\n",
        "    * a doctor does not order the Troponin-I lab test, because they believe it to be normal\n",
        "\n",
        "The hardest case to deal with is MNAR, and unfortunately, that is the most common in the medical domain. Still, we have to do something, so we often use approaches which are theoretically invalid under MNAR but in practice work acceptably well.\n",
        "\n",
        "Below, we'll replace missing data with the average value for the training population."
      ],
      "metadata": {
        "id": "7ghcSDMkRGFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu = np.nanmean(X, axis=0)\n",
        "for i in range(5):\n",
        "  print(f'{features[i]}: {mu[i]:2.1f}')"
      ],
      "metadata": {
        "id": "qDORwddBRXxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4: What's wrong with the above approach?"
      ],
      "metadata": {
        "id": "A7yUeyqURYAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#A4: Data leakage! We use the test set values for estimating the mean.\n",
        "\n",
        "# since decision trees do not handle missing data, we impute it here\n",
        "mu = np.nanmean(X_train, axis=0)\n",
        "\n",
        "for i in range(X_train.shape[1]):\n",
        "    idxMissing = np.isnan(X_train[:, i])\n",
        "    X_train[idxMissing, i] = mu[i]\n",
        "\n",
        "    idxMissing = np.isnan(X_test[:, i])\n",
        "    X_test[idxMissing, i] = mu[i]\n",
        "\n",
        "# now we should find that we have no more missing data!\n",
        "\n",
        "print('Training size: {} - {:6d} missing observations'.format(X_train.shape,\n",
        "                                                           np.sum(np.sum(np.isnan(X_train)))))\n",
        "print('Test size:     {} - {:6d} missing observations'.format(X_test.shape,\n",
        "                                 np.sum(np.sum(np.isnan(X_test)))))"
      ],
      "metadata": {
        "id": "AQiPUXLnPuqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Idempotency\n",
        "\n",
        "Q5: What's wrong with keeping the above code as is?"
      ],
      "metadata": {
        "id": "nQPz5CHTj7J-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A5: I can very easily screw it all up by re-running everything out of order.\n",
        "\n",
        "If working locally, this can be avoided by writing functions in a separate .py file, and using `%load_ext` and `%autoreload 2`."
      ],
      "metadata": {
        "id": "l6kRS7GPkBYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(seta):\n",
        "  # remove cheating variables from training data\n",
        "  X = seta.drop(['In-hospital_death', 'Survival', 'Length_of_stay'], axis=1).values\n",
        "  y = seta['In-hospital_death'].values\n",
        "\n",
        "  # here we only use the first 2500 observations as our training set\n",
        "  y_train = y[0:2500]\n",
        "  X_train = X[0:2500, :]\n",
        "\n",
        "  y_test = y[2500:]\n",
        "  X_test = X[2500:, :]\n",
        "\n",
        "  features = list(seta.drop(['In-hospital_death', 'Survival', 'Length_of_stay'], axis=1).columns)\n",
        "\n",
        "  return X_train, y_train, X_test, y_test, features"
      ],
      "metadata": {
        "id": "FU5twtbokNa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision trees have high \"variance\"\n",
        "\n",
        "It will be useful to demonstrate how decision trees have high \"variance\". In this context, variance refers to a property of some models to have a wide range of performance given random samples of data. Let's take a look at randomly slicing the data we have too see what that means."
      ],
      "metadata": {
        "id": "NBSPRd5eRtqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(123)\n",
        "\n",
        "fig = plt.figure(figsize=[12,3])\n",
        "for i in range(3):\n",
        "    ax = fig.add_subplot(1,3,i+1)\n",
        "\n",
        "    # generate indices in a random order\n",
        "    idx = np.random.permutation(X_train.shape[0])\n",
        "\n",
        "    # only use the first 50\n",
        "    idx = idx[:50]\n",
        "    X_temp = X_train[idx, :2]\n",
        "    y_temp = y_train[idx]\n",
        "\n",
        "    # initialize the model\n",
        "    mdl = tree.DecisionTreeClassifier(max_depth=5)\n",
        "\n",
        "    # train the model using the dataset\n",
        "    mdl = mdl.fit(X_temp, y_temp)\n",
        "\n",
        "    # only specify labels once for clarity\n",
        "    xlabel = features[0] if i == 1 else None\n",
        "    ylabel = features[1] if i == 0 else None\n",
        "\n",
        "    plot_model_pred_2d(mdl, X_temp, y_temp, xlabel=xlabel, ylabel=ylabel, cbar=False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G6Kem-jZRu0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above we can see that we are using random subsets of data, and as a result, our decision boundary can change quite a bit.\n",
        "\n",
        "Let's build the model on the full training set."
      ],
      "metadata": {
        "id": "rNX5-gpNjWpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a decision tree classifier\n",
        "mdl_dt = tree.DecisionTreeClassifier(criterion='entropy', splitter='best')\n",
        "\n",
        "# Fit the model to the training data\n",
        "mdl_dt = mdl_dt.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the model on the test set\n",
        "yhat = mdl_dt.predict_proba(X_test)[:,1]\n",
        "score = metrics.roc_auc_score(y_test, yhat)\n",
        "\n",
        "print(f'Model AUROC on the test set: {score:1.3f}')"
      ],
      "metadata": {
        "id": "rieypeXtPunN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5: This was just one performance measure on a random 1000 cases. Are there techniques we can use to better evaluate how well this model would do on a held-out dataset?"
      ],
      "metadata": {
        "id": "4horL1cujzFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A5: Of course :)\n",
        "\n",
        "Cross-validation is a very common one."
      ],
      "metadata": {
        "id": "EanRgcBBj2CM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving the model\n",
        "\n",
        "Let's say we wanted to improve this model, either by:\n",
        "\n",
        "- doing cross-validation\n",
        "- tuning hyperparameters\n",
        "- changing the model type\n",
        "\n",
        "We would have to be very careful about the data leakage step above, particularly with respect to missing data. We'd have to write for loops and constantly reshuffle the data around. This would be tedious, and very error prone.\n",
        "\n",
        "Enter scikit-learn pipelines."
      ],
      "metadata": {
        "id": "TJtzYRh1k1PE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline\n",
        "\n",
        "A really great way of building models is to use `pipeline` from scikit-learn. This allows us to define the steps in our preprocessing *with* the ultimate model. It's a great feature that simplifies a lot of the tedium in preprocessing. Here's an example imputing missing data."
      ],
      "metadata": {
        "id": "La_Cac7zlVuv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hG0UGdQ1lXR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use pipeline to automatically apply preprocessing\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# choose the classifier\n",
        "base_mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best')\n",
        "\n",
        "# create a pipeline which imputes missing data, then runs the model\n",
        "mdl = Pipeline(\n",
        "    [\n",
        "        (\"preprocessor\", SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "        ('model', base_mdl)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# evaluate the model on the data - same as before!\n",
        "mdl = mdl.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the model on the test set\n",
        "yhat = mdl.predict_proba(X_test)[:, 1]\n",
        "score = metrics.roc_auc_score(y_test, yhat)\n",
        "\n",
        "print(f'Model AUROC on the test set: {score:1.3f}')"
      ],
      "metadata": {
        "id": "sIjMVC7RliTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have a pipeline setup, we can actually use it with the original data, as our pipeline will impute the data for us. We can use another scikit-learn tool, cross_val_score, to evaluate the AUROC across cross-validation folds."
      ],
      "metadata": {
        "id": "O7ZRJNipmBSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(mdl, X, y, cv=5, scoring='roc_auc')\n",
        "print(\"AUROC: {:0.3f} [{:0.3f}, {:0.3f}]\".format(np.mean(scores), np.min(scores), np.max(scores)))"
      ],
      "metadata": {
        "id": "kpPlThF-mENy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to tune hyper-parameters, there is this helpful guide:\n",
        "https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
        "\n",
        "Let's try to tune the max_depth parameter of our decision tree."
      ],
      "metadata": {
        "id": "j7XmPFaMmY1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'model__max_depth': [None, 3, 5, 10]}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=mdl,\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "print(\"Performing grid search...\")\n",
        "print(\"Hyperparameters to be evaluated:\")\n",
        "pprint(param_grid)\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "\n",
        "print(\"\\n===\\nBest parameters combination found:\")\n",
        "best_parameters = grid_search.best_estimator_.get_params()\n",
        "for param_name in sorted(best_parameters.keys()):\n",
        "    print(f\"{param_name}: {best_parameters[param_name]}\")\n",
        "print(\"===\\n\")\n",
        "test_auroc = grid_search.score(X_test, y_test)\n",
        "print(\n",
        "    \"AUROC of the best parameters using the inner CV of \"\n",
        "    f\"the random search: {grid_search.best_score_:.3f}\"\n",
        ")\n",
        "print(f\"AUROC on test set: {test_auroc:.3f}\")"
      ],
      "metadata": {
        "id": "h9-PdkDsmedU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can make custom pipelins which preprocess segments of the data separately."
      ],
      "metadata": {
        "id": "QLymMpMsmT0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use pipeline to automatically apply preprocessing\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Let's define the features we want to use here\n",
        "\n",
        "# below says \"all features in the dataset, except these three\"\n",
        "# model_features = [x for x in seta.columns if x not in ['Length_of_stay', 'Survival', 'In-hospital_death']]\n",
        "\n",
        "model_features = [\n",
        "  'Age', 'Gender', 'Height', 'Weight',\n",
        "  'CCU', 'SysABP_last', 'TroponinI_last', 'MechVentDuration'\n",
        "]\n",
        "target_feature = 'In-hospital_death'\n",
        "\n",
        "base_mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=3)\n",
        "\n",
        "# our pipeline will\n",
        "#  (1) impute 0 if MechVentDuration is missing - since that implies no mech vent\n",
        "#  (2) impute the mean for continuous variables - Imputer\n",
        "mechvent_features = [x for x in ['MechVentStartTime', 'MechVentDuration', 'MechVentLast8Hour'] if x in model_features]\n",
        "\n",
        "# be sure to exclude the mechvent features from our numeric features\n",
        "numeric_features = [x for x in model_features if x not in mechvent_features]\n",
        "\n",
        "# We create separate preprocessing pipelines for numeric and categorical data.\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "mechvent_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value=0))\n",
        "])\n",
        "\n",
        "# You could also consider a transformer which converts categorical data into a bunch of features of 0s/1s\n",
        "# so called \"one-hot\" encoding\n",
        "#categorical_transformer = Pipeline(steps=[\n",
        "#    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
        "#    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "#])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('mv', mechvent_transformer, mechvent_features)])\n",
        "\n",
        "mdl = Pipeline([(\"preprocessor\", preprocessor),\n",
        "                ('model', base_mdl)])"
      ],
      "metadata": {
        "id": "0DdyaFImlZ9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the above pipeline on the data, and evaluate it in cross-validation."
      ],
      "metadata": {
        "id": "xFqm62Wanu2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(mdl, seta[model_features], seta[target_feature], cv=5, scoring='roc_auc')\n",
        "print(\"AUROC: {:0.3f} [{:0.3f}, {:0.3f}]\".format(np.mean(scores), np.min(scores), np.max(scores)))"
      ],
      "metadata": {
        "id": "fZMilozmnwiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keep exploring!\n",
        "\n",
        "* Are there other ways to impute missing data?\n",
        "* Have we thought about the features in our data, and how we are using them?\n",
        "* Have we visualized the data? Are there any obvious outliers which may fool our model?\n",
        "  *  Note: a lot of outliers were removed by custom preprocessing I did, but some may remain\n",
        "* Are there parameters of our model which we could change?\n",
        "* Is there a systematic way of choosing the parameters of our model?\n",
        "\n",
        "The below code downloads a second set of data - `set-b`. This is the same type of data from a distinct 4000 patients, but this time you don't have the answers!"
      ],
      "metadata": {
        "id": "RDfNUfw3lMXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://github.com/alistairewj/tree-prediction-tutorial/raw/master/data/PhysionetChallenge2012-set-b-no-outcome.csv.gz'\n",
        "setb = pd.read_csv(url, sep=',', header=0, compression='gzip')\n",
        "setb.set_index('recordid', inplace=True)\n",
        "setb.head()"
      ],
      "metadata": {
        "id": "hQC_V0_qlMd_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}